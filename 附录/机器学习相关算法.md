### 相关算法比较
#### 1.决策树（Decision Tree）
>>在进行逐步应答过程中，典型的决策树分析会使用分层变量或决策节点。例如：可将一个给定用户分类成信用可靠或不可靠。

>优点：擅长对人、地点、事物的一系列不同特征、品质、特性进行评估。

>场景举例：基于规则的信用评估、赛马结果预测。

>扩展阅读：《从头开始：用Python实现决策树算法》《想了解概率图模型？你要先了解图论的基本定义与形式》
#### 2.支持向量机（Support Vector Machine）
>>基于超平面（hyperplane），支持向量机可以对数据群进行分类

>优点：支持向量机擅长在变量X与其它变量之间进行二元分类操作，无论其关系是否是线性的。

>场景举例：新闻分类、手写识别。

>扩展阅读：《详解支持向量机（附学习资源）》
#### 3.回归（Regression）
>>回归可以勾画出因变量与一个或多个应变量之间的状态关系。如：将垃圾邮件和非垃圾邮件进行了区分。

>优点：回归可用于识别变量之间的连续关系。即使不明显。

>场景举例：路面交通模型分析、邮件过滤。
#### 4.朴素贝叶斯分类（Naive Bayes Classification）
>>朴素贝叶斯分类器用于计算可能条件的分支概率。每个独立的特征都是朴素或条件独立的，因此他们不会影响别的对象。如：在一个装有5个黄色和红色小球的罐子里，连续拿到两个黄色小球的概率是多少？前后抓取两个黄色小球的概率为1/10.朴素贝叶斯分类器可以计算多个特征的量和条件概率。

>优点：对于在小数据集上有显著特征的相关对象，朴素贝叶斯方法可对其进行快速分类。

>场景举例：情感分析、消费者分类。
#### 5.隐马尔可夫模型（Hidden Markov Model）
>>显马尔可夫过程是完全确定性的——一个给定的状态经常会伴随另一个状态。如：交通信号灯。相反，隐马尔可夫模型通过分析可见数据来计算隐藏状态的发生，随后借助隐藏状态分析，隐马尔可夫模型可以估计可能的未来管产模式。如：通过高低气压的概率来预测晴天、雨天、多云天气的概率。

>优点：容许数据的变化性，适用于识别和预测操作。

>场景举例：面部表情分析、预测操作。
#### 6.随机森林（Random Forest）
>>随机森林算法通过使用多个带有随机选取的数据子集的树改善了决策树的精确性。如：在基因表达层面考察大量与乳腺癌复发相关的基因，计算出复发风险。

>优点：随机森林方法被证明对大规模数据集和存在大量且有时不相关特征的项来说很有用。

>场景举例：用户流失分析、风险评估。

>扩展阅读：《从头开始：用Python实现随机森林算法》
#### 7.循环神经网络（Recurrent Neural Network）
>>在任意神经网络中，每个神经元都通过一个或多个隐藏层来将很多输入转换成单个输出。循环神经网络会将值进一步逐层传递，让逐层学习成为可能。换句话说，RNN存在某种形式的记忆，允许先前的输出去影响后面的输入。

>优点：循环神经网络在存在大量有序信息时具有预测能力。

>场景举例：图像分类与字幕添加、政治情感分析。
#### 8.长短期记忆（Long Short-Term Memory）与门控循环单元神经网络（Gated Recurrent Unit Neural Network）
>>早期的RNN形式存在损耗。尽管早期循环神经网络只允许留存少量的早期信息。LSTM与GRU都有有长期与短期的记忆。换句话说，新近的RNN拥有更好的控制记忆的能力，允许保留早先的值或是当有必要处理很多系列步骤时重置这些值，这避免了梯度衰减或逐层传递的值最终degradation。LSTM与GRU网络是我们可以使用被称为门的记忆模块或结构来控制记忆。这种门可以在合适的时候传递或重置值。

>优点：LSTM和GRU具备与其它循环神经网络一样的优点，但拥有更好的记忆能力，所以更常被使用。

>场景举例：自然语言处理、翻译。

>扩展阅读：《LSTM和递归网络基础教程》《图解LSTM神经网络架构及其11中变体》
>####9.卷积神经网络（Convolutional Neural Network）
>
>>卷积是指来自后续层的权重的融合，可用于标记输出层。

>优点：当存在非常大型的数据集、大量特征和复杂的分类任务时，卷积神经网络非常有用。

>场景举例：图像识别、文本转语音、药物发现。

>扩展阅读：《卷积神经网络简介》《从入门到精通：卷积神经网络初学者指南》和《解析深度卷积神经网络的14中设计模式》